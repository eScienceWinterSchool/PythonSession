{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.imgur.com/hkb7Bq7.png\" width=\"500\"></center>\n",
    "\n",
    "\n",
    "### **Prof. José Manuel Magallanes, PhD**\n",
    "\n",
    "* Professor, Departamento de Ciencias Sociales, Pontificia Universidad Católica del Perú, [jmagallanes@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe)\n",
    "\n",
    "* Visiting Professor, Evans School of Public Policy and Governance / Senior Data Science Fellow, eScience Institute, University of Washington, [magajm@uw.edu](mailto:magajm@uw.edu)\n",
    "_____\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Python\n",
    "\n",
    "### Using Python for Pre Processing\n",
    "\n",
    "In the session we will see the use of Python to:\n",
    "\n",
    "1. Collect data as dataframes into Python\n",
    "\n",
    "2. Preprocess a data frame:\n",
    "    * Subset data\n",
    "    * Fix column names\n",
    "    * Look for non-standar missing values\n",
    "    * Clean cell values\n",
    "    * Format data types\n",
    "\n",
    "\n",
    "3. Merge both tables\n",
    "\n",
    "\n",
    "4. Prepare a file for further analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect data tables into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of data file\n",
    "linkFile=\"https://hdr.undp.org/sites/default/files/2021-22_HDR/HDR21-22_Statistical_Annex_HDI_Table.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in a table from a file using pandas, since it is an Excel file, I requires **openpyxl**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available in my computer?\n",
    "!pip show openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not available, please go to Anaconda and install it. Once installed, or if available, continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the right function:\n",
    "import pandas as pd\n",
    "\n",
    "hdiFile=pd.read_excel(linkFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_options = {'User-Agent': 'Mozilla/5.0'}\n",
    "hdiFile = pd.read_excel(linkFile, storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing\n",
    "\n",
    "### Subset data\n",
    "\n",
    "Just keep what you need; let's check the data head and tail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you do not see countries neither in the first rows nor in the last ones. There are rows at the begining and at the end that are not needed. \n",
    "\n",
    "Let's find the row indexes that have the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the problem is at the tail:\n",
    "hdiFile.tail(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this better?\n",
    "hdiFile.iloc[7:206,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting as new DF (copy)\n",
    "hdiRaw=hdiFile.iloc[7:206,:].copy()\n",
    "hdiRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix column names\n",
    "\n",
    "Notice that **hdiRaw** do not have the right column names. So we need to recover them from **hdiFile**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.iloc[[3,4],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the column names are in different positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and\n",
    "hdiFile.iloc[4,:2].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.iloc[3,2:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save column names \n",
    "RealHeaders=hdiFile.iloc[4,:2].to_list()+hdiFile.iloc[3,2:].to_list()\n",
    "# these are:\n",
    "RealHeaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's avoid all the \"ranks\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RealHeaders[1:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for the first one\n",
    "hdiRaw=hdiRaw.iloc[:,1:-3]\n",
    "hdiRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's just use the column names needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiRaw.columns=RealHeaders[1:-3]\n",
    "hdiRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have column names with missing values, let's get rid of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BetterHeaders=hdiRaw.columns.dropna().to_list()\n",
    "BetterHeaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting again\n",
    "hdiRaw=hdiRaw.loc[:,BetterHeaders]\n",
    "hdiRaw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that the columns:\n",
    "* Have acronyms in parenthesis.\n",
    "* Have spaces between words.\n",
    "\n",
    "Let's see what can be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye anything between parenthesis\n",
    "hdiRaw.columns.str.replace('\\(.+\\)',\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye anything between parenthesis, bye leading-trailing spaces\n",
    "hdiRaw.columns.str.replace('\\(.+\\)',\"\", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye anything between parenthesis, bye leading-trailing spaces, title case\n",
    "hdiRaw.columns.str.replace('\\(.+\\)',\"\", regex=True).\\\n",
    "                          str.strip().\\\n",
    "                          str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep this last one for a while:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing column names\n",
    "hdiRaw.columns=hdiRaw.columns.str.replace('\\(.+\\)',\"\", regex=True).\\\n",
    "                          str.strip().\\\n",
    "                          str.title()\n",
    "#so\n",
    "hdiRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to decide how the we want as the shorter column name:\n",
    "\n",
    "* Same title without spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiRaw.columns.str.replace(\" \",'',regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some acronyms: Let's do this step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each column names splitted:\n",
    "[name.split() for name in hdiRaw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first letter of each word\n",
    "[[word[0] for word in name.split()] for name in hdiRaw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final result\n",
    "[''.join([word[0] for word in name.split()]) for name in hdiRaw.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the first alternative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiRaw.columns=hdiRaw.columns.str.replace(\" \",'',regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for non-standar missing values\n",
    "\n",
    "First check a cell that is full of non-word/non-digit characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full match!\n",
    "[hdiRaw.iloc[:,1].str.fullmatch(\"\\W+\",na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result is telling you if whether there is or there is not a full match (True/False). You can use that to keep the rows where this is _True_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick look...\n",
    "hdiRaw.iloc[:,1][hdiRaw.iloc[:,1].str.fullmatch(\"\\W+\",na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this for every column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "hdiRaw.iloc[:,i][hdiRaw.iloc[:,i].str.fullmatch(\"\\W+\",na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "hdiRaw.iloc[:,i][hdiRaw.iloc[:,i].str.fullmatch(\"\\W+\",na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **for** loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hdiRaw.shape[1]):\n",
    "    print(hdiRaw.iloc[:,i][hdiRaw.iloc[:,i].str.fullmatch(\"\\W+\",na=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **try**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hdiRaw.shape[1]):\n",
    "    try:\n",
    "        print(hdiRaw.iloc[:,i][hdiRaw.iloc[:,i].str.fullmatch(\"\\W+\",na=False)])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the people who created this data set used \"..\" to represent **missing values**. Let's replace those values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiRaw.replace(to_replace=[\"..\"],\n",
    "                value=None,inplace=True)\n",
    "hdiRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning cell values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the current cell values have issues?\n",
    "\n",
    "* Keeping complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with all missing (after the first column)\n",
    "hdiRaw[hdiRaw.iloc[:,1:].isna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with at least one missing (after the first column)\n",
    "hdiRaw[hdiRaw.iloc[:,1:].isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiComplete=hdiRaw[~hdiRaw.iloc[:,1:].isna().any(axis=1)].copy()\n",
    "#\n",
    "hdiComplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Making sure text is clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of leading and trailing spaces in text cells\n",
    "hdiComplete.Country=hdiComplete.Country.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking  numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiComplete.iloc[:,1:].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers have been recognised as **object** type. It might be due to having a non numeric value in one cell, or because it **had** a non-numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can you apply math?\n",
    "hdiRaw.iloc[:,1:].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just need to give format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiClean=hdiComplete.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we just need to format the numeric columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Formatting into numeric type**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as easy as:\n",
    "hdiClean[hdiClean.columns[1:]]=hdiClean.iloc[:,1:].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recheck\n",
    "hdiClean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFormat=hdiClean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: Integrating and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demoFormat=pd.read_pickle(\"demoFormat.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be an easy step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFormat.merge(demoFormat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice you have lost countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hdiFormat),len(demoFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyHDI=set(hdiFormat.Country)-set(demoFormat.Country)\n",
    "onlyDEMO=set(demoFormat.Country)-set(hdiFormat.Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyHDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyDEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for good matches, using **thefuzz** (might need to be installed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process as fz\n",
    "\n",
    "# look for a country in OnlyHDI and return the most similar\n",
    "[(fz.extractOne(demo, onlyHDI),demo) for demo in sorted(onlyDEMO)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(fz.extractOne(demo, onlyHDI),demo) for demo in sorted(onlyDEMO) \\\n",
    " if fz.extractOne(demo, onlyHDI)[1]>=90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recover those above. For that, you need to create a **dictionary of changes**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{fz.extractOne(demo, onlyHDI)[0]:demo for demo in sorted(onlyDEMO) \\\n",
    " if fz.extractOne(demo, onlyHDI)[1]>=90}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the object\n",
    "changesHDI={fz.extractOne(demo, onlyHDI)[0]:demo \\\n",
    "            for demo in sorted(onlyDEMO) \\\n",
    "            if fz.extractOne(demo, onlyHDI)[1]>=90}\n",
    "\n",
    "# replace in HDI\n",
    "\n",
    "hdiFormat.Country.replace(to_replace=changesHDI,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many matches?\n",
    "hdiFormat.merge(demoFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should we do it again?\n",
    "\n",
    "onlyHDI=set(hdiFormat.Country)-set(demoFormat.Country)\n",
    "onlyDEMO=set(demoFormat.Country)-set(hdiFormat.Country)\n",
    "\n",
    "[(fz.extractOne(demo, onlyHDI),demo) for demo in sorted(onlyDEMO)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{fz.extractOne(demo, onlyHDI)[0]:demo for demo in sorted(onlyDEMO) \\\n",
    " if (fz.extractOne(demo, onlyHDI)[1]<86)&\\\n",
    "    (fz.extractOne(demo, onlyHDI)[1]>45)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesHDI2={fz.extractOne(demo, onlyHDI)[0]:demo for demo in sorted(onlyDEMO) \\\n",
    " if (fz.extractOne(demo, onlyHDI)[1]<86)&\\\n",
    "    (fz.extractOne(demo, onlyHDI)[1]>45)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually\n",
    "changesHDI2.update({'Korea (Republic of)':'South Korea'})\n",
    "changesHDI2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now\n",
    "hdiFormat.Country.replace(to_replace=changesHDI2,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem=hdiFormat.merge(demoFormat)\n",
    "# result:\n",
    "hdidem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "\n",
    "\n",
    "### <font color=\"red\">Saving File to Disk</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future use in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem.to_pickle(\"hdidemocia.pkl\")\n",
    "# you will need: DF=pd.read_pickle(\"hdidemocia.pkl\")\n",
    "# or:\n",
    "# from urllib.request import urlopen\n",
    "# DF=pd.read_pickle(urlopen(\"https://...../hdidemocia.pkl\"),compression=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future  use in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr('base')\n",
    "base.saveRDS(hdidem,file=\"hdidem.RDS\")\n",
    "\n",
    "#In R, you call it with: DF = readRDS(\"hdidem.RDS\")\n",
    "#or, if iyou read from cloud: DF = readRDS(url(\"https://...../hdidem.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
