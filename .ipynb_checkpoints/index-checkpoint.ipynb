{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.imgur.com/hkb7Bq7.png\" width=\"500\"></center>\n",
    "\n",
    "\n",
    "### **Prof. José Manuel Magallanes, PhD**\n",
    "\n",
    "* Professor, Departamento de Ciencias Sociales, Pontificia Universidad Católica del Perú, [jmagallanes@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe)\n",
    "\n",
    "* Visiting Professor, Evans School of Public Policy and Governance / Senior Data Science Fellow, eScience Institute, University of Washington, [magajm@uw.edu](mailto:magajm@uw.edu)\n",
    "_____\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='home'></a>\n",
    "\n",
    "# Introduction to Python\n",
    "\n",
    "### Using Python for Pre Processing\n",
    "\n",
    "In the session we will see the use of Python to:\n",
    "\n",
    "1. Collect data as dataframes into Python\n",
    "\n",
    "2. Preprocess a data frame:\n",
    "    * [Fix column names](#fixcolnames)\n",
    "    * [Subset data](#subset)    \n",
    "    * [Look for non-standar missing values](#lookfornas)\n",
    "    * [Missing values](#missingcellvalues)\n",
    "    * [Format data types](#formatdtypes)\n",
    "\n",
    "\n",
    "3. Merge both tables:\n",
    "    * [Basic merge](#merging)\n",
    "    * [Fuzzy merge](#fuzzmerging)\n",
    "\n",
    "\n",
    "4. Prepare a file for further analysis\n",
    "    * [Scaling](#scaling)\n",
    "    * [Exporting](#exporting)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect data tables into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of data file\n",
    "linkFile=\"https://github.com/eScienceWinterSchool/PythonSession/raw/master/data/HDR21-22_Statistical_Annex_HDI_Table.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in a table from a file using pandas, since it is an Excel file, I requires **openpyxl**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available in my computer?\n",
    "!pip show openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not available, please go to Anaconda and install it. Once installed, or if available, continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the right function:\n",
    "import pandas as pd\n",
    "\n",
    "hdiFile=pd.read_excel(linkFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "## 2.  Pre Processing\n",
    "\n",
    "<a id='fixcolnames'></a>\n",
    "\n",
    "### Fix column names\n",
    "\n",
    "Notice that we do not have the right column names. So we need to save them before we go on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.iloc[[3,4],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the column names are in different positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and\n",
    "hdiFile.iloc[4,:2].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.iloc[3,2:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save column names \n",
    "RealHeaders=hdiFile.iloc[4,:2].to_list()+hdiFile.iloc[3,2:].to_list()\n",
    "# these are:\n",
    "RealHeaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.columns=RealHeaders\n",
    "hdiFile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the repeated column names, and that we do not need the last three columns. Let's solve that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.iloc[:,:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then,\n",
    "hdiFile=hdiFile.iloc[:,:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have column names with missing values, let's get rid of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BetterHeaders=hdiFile.columns.dropna().to_list()\n",
    "#result\n",
    "BetterHeaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting again\n",
    "hdiFile=hdiFile.loc[:,BetterHeaders]\n",
    "hdiFile.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that the columns:\n",
    "* Have acronyms in parenthesis.\n",
    "* Have spaces between words.\n",
    "\n",
    "Let's see what can be done using _Regular Expressions_ (REGEX):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye anything between parenthesis\n",
    "hdiFile.columns.str.replace('\\(.+\\)',\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye anything between parenthesis, bye leading-trailing spaces\n",
    "hdiFile.columns.str.replace('\\(.+\\)',\"\", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye anything between parenthesis, bye leading-trailing spaces, title case\n",
    "hdiFile.columns.str.replace('\\(.+\\)',\"\", regex=True).\\\n",
    "                          str.strip().\\\n",
    "                          str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep this last one for a while:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing column names\n",
    "hdiFile.columns=hdiFile.columns.str.replace('\\(.+\\)',\"\", regex=True).\\\n",
    "                          str.strip().\\\n",
    "                          str.title()\n",
    "#so\n",
    "hdiFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to decide how the we want as the shorter column name:\n",
    "\n",
    "* Same title without spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.columns.str.replace(\" \",'',regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some acronyms: Let's do this step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each column names splitted:\n",
    "[name.split() for name in hdiFile.columns[2::]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first letter of each word\n",
    "[[word[0] for word in name.split()] for name in hdiFile.columns[2::]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final result\n",
    "[''.join([word[0] for word in name.split()]) for name in hdiFile.columns[2::]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the last alternative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNames=[''.join([word[0] for word in name.split()]) for name in hdiFile.columns[2::]]\n",
    "hdiFile.columns=hdiFile.columns[:2].to_list()+newNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdiFile.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "<a id='subset'></a>\n",
    "\n",
    "### Subset data\n",
    "\n",
    "After becoming familar with the data, we know we should keep countries with ranking value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile[~pd.isna(hdiFile['Hdi Rank'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then\n",
    "hdiFile=hdiFile[~pd.isna(hdiFile['Hdi Rank'])]\n",
    "\n",
    "#see\n",
    "hdiFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a bad row data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.drop(index=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just drop it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiSubset=hdiFile.drop(index=4)\n",
    "hdiSubset.reset_index(drop=True, inplace=True)\n",
    "#see\n",
    "hdiSubset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "<a id='lookfornas'></a>\n",
    "\n",
    "### Look for non-standar missing values\n",
    "\n",
    "First check a cell that is full of non-word/non-digit characters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **try**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hdiSubset.shape[1]):\n",
    "    try:\n",
    "        print(hdiSubset.iloc[:,i][hdiSubset.iloc[:,i].str.fullmatch(\"\\W+\",na=False)])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have weird symbols, but if we had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing !\n",
    "\n",
    "badSymbols=[\"..\",'xx','tba']\n",
    "hdiSubset.replace(to_replace=badSymbols,\n",
    "               value=None,\n",
    "               inplace=True)\n",
    "\n",
    "#result\n",
    "hdiSubset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "<a id='missingcellvalues'></a>\n",
    "\n",
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the current cell values have issues?\n",
    "\n",
    "* Keeping complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with all missing (after the first column)\n",
    "hdiSubset[hdiSubset.iloc[:,1:].isna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with at least one missing (after the first column)\n",
    "hdiSubset[hdiSubset.iloc[:,1:].isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Making sure columns of _text_ are clean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of leading and trailing spaces in text cells\n",
    "hdiSubset.Country=hdiSubset.Country.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking  numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiSubset.drop(columns=['Country'], axis=0).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers have been recognised as **object** type. It might be due to having a non numeric value in one cell, or because it **had** a non-numeric value before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can you apply math?\n",
    "hdiSubset.drop(columns=['Country'], axis=0).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just need to give format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiClean=hdiSubset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "<a id='formatdtypes'></a>\n",
    "\n",
    "### Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we just need to format the numeric columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Formatting into numeric type**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep all numeric columns\n",
    "\n",
    "allCols=hdiClean.columns.to_list()\n",
    "allCols.remove('Country')\n",
    "allCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as easy as:\n",
    "hdiClean[allCols]=hdiClean[allCols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recheck\n",
    "hdiClean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFormat=hdiClean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "\n",
    "## 3. Integrating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me bring another table, this time from [wikipedia](https://en.wikipedia.org/wiki/The_Economist_Democracy_Index#Components). Make sure to have **html5lib** and **beautifulsoup4** installed before the next code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkwiki='https://en.wikipedia.org/wiki/The_Economist_Democracy_Index'\n",
    "sortableTables=pd.read_html(io=linkwiki,flavor='bs4',attrs={\"class\": \"wikitable sortable\"})\n",
    "\n",
    "# we got\n",
    "type(sortableTables), len(sortableTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the third one\n",
    "sortableTables[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this the one\n",
    "demoTable=sortableTables[2].copy()\n",
    "\n",
    "# check columns\n",
    "demoTable.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demoTable.columns.str.contains('Δ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demoTable.columns[~demoTable.columns.str.contains('Δ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep some:\n",
    "someCols=demoTable.columns[~demoTable.columns.str.contains('Δ')]\n",
    "\n",
    "#subset\n",
    "demoSub=demoTable[someCols].copy()\n",
    "\n",
    "#then\n",
    "demoSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demoSub.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "<a id='merging'></a>\n",
    "\n",
    "### Basic merging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are confident we did a good cleaning and formatting, this step should be easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_on= / right_on NOT NEEDED (only when column names differ)\n",
    "hdiFormat.merge(demoSub,left_on='Country', right_on='Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the amount of rowd **returned above**, and compare it with the amount of rows in each data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hdiFormat),len(demoSub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not want to check country names, you stop here.\n",
    "\n",
    "[Home](#home)\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fuzzmerging'></a>\n",
    "\n",
    "### Fuzzy Merge\n",
    "\n",
    "\n",
    "The smallest amount of rows between two tables, is the maximum amount you expect after the merge. Let's check the key values that were not matched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyHDI=set(hdiFormat.Country)-set(demoSub.Country)\n",
    "onlyDEMO=set(demoSub.Country)-set(hdiFormat.Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyHDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyDEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous objects (onlyDEMO, onlyHDI) inform the values not matched in the other data frames. \n",
    "If you want to recover some of these values, you may follow these steps (you may need to install **thefuzz**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process as fz\n",
    "\n",
    "# take a country from onlyDEMO\n",
    "# and get the country that matches the most in OnlyHDI\n",
    "\n",
    "[(demo,fz.extractOne(demo, onlyHDI)) for demo in sorted(onlyDEMO)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will not get the best outcome in this step, so you just need to keep the 'safe' matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(demo,fz.extractOne(demo, onlyHDI)) for demo in sorted(onlyDEMO) \\\n",
    " if fz.extractOne(demo, onlyHDI)[1]>=90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is replace the cells values in one of the data frames.\n",
    "For that, you need to create a **dictionary of changes**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary is prepared for HDI data:\n",
    "{demo:fz.extractOne(demo, onlyHDI)[0] for demo in sorted(onlyDEMO) \\\n",
    " if fz.extractOne(demo, onlyHDI)[1]>=90}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW create the dict and make the changes\n",
    "changesDEMO={demo:fz.extractOne(demo, onlyHDI)[0] for demo in sorted(onlyDEMO) \\\n",
    "             if fz.extractOne(demo, onlyHDI)[1]>=90}\n",
    "\n",
    "# replace in democracy\n",
    "\n",
    "demoSub.Country.replace(to_replace=changesDEMO,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did you get more rows?\n",
    "hdiFormat.merge(demoSub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you redo this process, you may recover more rows. I will not do it here, but you are welcome to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: start with these two lines!\n",
    "onlyHDI=set(hdiFormat.Country)-set(demoSub.Country)\n",
    "onlyDEMO=set(demoSub.Country)-set(hdiFormat.Country)\n",
    "#check\n",
    "[(demo,fz.extractOne(demo, onlyHDI)) for demo in sorted(onlyDEMO)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do some changes manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesDEMO={'Cape Verde':'Cabo Verde',\n",
    "             'Czech Republic':'Czechia',\n",
    "             'East Timor':'Timor-Leste',\n",
    "             'Ivory Coast':\"Côte d'Ivoire\",\n",
    "             'Laos':\"Lao People's Democratic Republic\", \n",
    "             'South Korea':'Korea (Republic of)',\n",
    "            'Turkey':'Türkiye'}\n",
    "\n",
    "# replace in democracy\n",
    "\n",
    "demoSub.Country.replace(to_replace=changesDEMO,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was the best that could be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem=hdiFormat.merge(demoSub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format should still be good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "\n",
    "## Prepare file for further work\n",
    "\n",
    "<a id='scaling'></a>\n",
    "\n",
    "###  Scaling\n",
    "\n",
    "It would be good to check the range of values of your numeric data. You can simply use **describe** (just requesting _min_ and _max_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem.describe().loc[['min','max']].T #T for transposing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see different ranges, it would be good to request a **boxplot** (make sure to install **matplotlib** if not previously installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hdidem.plot(kind='box', rot=90,fontsize=5)\n",
    "plt.semilogy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our concern is the numeric data. In case of categorical it is unusual to worry about it, but some cases might need some thinking.\n",
    "\n",
    "Let me get the column names of the numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "colsToScale = hdidem.select_dtypes([np.number]).columns\n",
    "\n",
    "colsToScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to produce new ranges (make sure you have previously install **scikit-learn**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_minmax = scaler.fit_transform(hdidem.loc[:,colsToScale].to_numpy())\n",
    "df_scaled = pd.DataFrame(df_minmax, columns=colsToScale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_scaled.describe().loc[['min','max']].T \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.plot(kind='box', rot=90,fontsize=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a suffix to the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.columns=df_scaled.columns+\"_mM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat to the right (instead of bottom) with axis=1\n",
    "pd.concat([hdidem,df_scaled],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is our last version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem_plus=pd.concat([hdidem,df_scaled],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "\n",
    "<a id='exporting'></a>\n",
    "\n",
    "### Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future use in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem_plus_plus.to_pickle(\"hdidem_plus.pkl\")\n",
    "# you will need: DF=pd.read_pickle(\"hdidem_plus.pkl\")\n",
    "# or:\n",
    "# from urllib.request import urlopen\n",
    "# DF=pd.read_pickle(urlopen(\"https://...../hdidem_plus.pkl\"),compression=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future  use in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr('base')\n",
    "base.saveRDS(hdidem_plus,file=\"hdidem_plus.RDS\")\n",
    "\n",
    "#In R, you call it with: DF = readRDS(\"hdidem_plus.RDS\")\n",
    "#or, if read from cloud: DF = readRDS(url(\"https://...../hdidem_plus.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
