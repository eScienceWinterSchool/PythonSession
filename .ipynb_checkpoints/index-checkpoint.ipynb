{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.imgur.com/hkb7Bq7.png\" width=\"500\"></center>\n",
    "\n",
    "\n",
    "### **Prof. José Manuel Magallanes, PhD**\n",
    "\n",
    "* Professor, Departamento de Ciencias Sociales, Pontificia Universidad Católica del Perú, [jmagallanes@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe)\n",
    "\n",
    "* Visiting Professor, Evans School of Public Policy and Governance / Senior Data Science Fellow, eScience Institute, University of Washington, [magajm@uw.edu](mailto:magajm@uw.edu)\n",
    "_____\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='home'></a>\n",
    "\n",
    "\n",
    "# Using Python for Pre Processing\n",
    "\n",
    "In the session we will see the use of Python to:\n",
    "\n",
    "1. Collect data as dataframes into Python\n",
    "    * [upload table](#upload)\n",
    "    * [scrape table](#scrape)    \n",
    "\n",
    "2. Clean data:\n",
    "    * [Fix column names](#fixcolnames)\n",
    "    * [Subset data](#subset)    \n",
    "    * [Missing values](#missing)\n",
    "\n",
    "3. [Format data types](#formatdtypes)\n",
    "\n",
    "\n",
    "4. Merge both tables:\n",
    "    * [Basic merge](#merging)\n",
    "    * [Fuzzy merge](#fuzzmerging)\n",
    "\n",
    "\n",
    "5. Prepare a file for further analysis\n",
    "    * [Scaling](#scaling)\n",
    "    * [Exporting](#exporting)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect data tables into Python\n",
    "\n",
    "<a id='upload'></a>\n",
    "\n",
    "### 1.1 Upload a File (Human Development Index)\n",
    "\n",
    "I have the data in a cloud folder, which I downloaded from this [link](https://hdr.undp.org/data-center/documentation-and-downloads) (_Table 1_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of data file\n",
    "linkFile=\"https://github.com/eScienceWinterSchool/PythonSession/raw/master/data/HDI_Table.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in a table from a file using pandas, since it is an Excel file, I requires **openpyxl**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available in my computer?\n",
    "!pip show openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not available, please go to Anaconda and install it. Once installed, or if available, continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hdiFile=pd.read_excel(linkFile) # only for excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look (as it is in Excel, it might be a good idea to see it in from Excel too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scrape'></a>\n",
    "\n",
    "### 1.2 Scrape a Table (The Economist Democracy Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me bring another table, this time from [wikipedia](https://en.wikipedia.org/wiki/The_Economist_Democracy_Index#Components). Make sure to have **html5lib** and **beautifulsoup4** installed before the next code (use **pip show**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show html5lib beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now bring the tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path\n",
    "linkwiki='https://en.wikipedia.org/wiki/The_Economist_Democracy_Index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call\n",
    "sortableTables=pd.read_html(io=linkwiki,# this is the link to main webpage\n",
    "                            flavor='bs4',# you want pandas to use bs4\n",
    "                            attrs={\"class\": \"wikitable sortable\"}) # an attribute of the table to scrape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice:\n",
    "\n",
    "- The result **sortableTables** is NOT the data frame you expect. \n",
    "- **sortableTables** is a _list_ of all the tables found that match the attributes (_attrs_ above)\n",
    "\n",
    "Pay attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what you got, and many you got\n",
    "type(sortableTables), len(sortableTables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three tables, let's see one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the second one\n",
    "sortableTables[1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the third one\n",
    "sortableTables[2].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the right one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this the one\n",
    "demoTable=sortableTables[2].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "## 2.  Cleaning\n",
    "\n",
    "<a id='fixcolnames'></a>\n",
    "\n",
    "### Fix column names\n",
    "\n",
    "* **Put them in the right place**\n",
    "\n",
    "Notice that we do not have the right column names. So we need to save them before we go on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiFile.iloc[[3,4],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the column names are in different positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here\n",
    "hdiFile.iloc[3,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here\n",
    "hdiFile.iloc[4,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we _concatenate_ those values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save column names \n",
    "RealHeaders=hdiFile.iloc[4,:2]+hdiFile.iloc[3,2:]\n",
    "# these are:\n",
    "RealHeaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easier if we have lists, so we use **.to_list()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save column names turned to lists\n",
    "RealHeaders=hdiFile.iloc[4,:2].to_list()+hdiFile.iloc[3,2:].to_list()\n",
    "# these are:\n",
    "RealHeaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it looks now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all the columns\n",
    "hdiFile.columns=RealHeaders\n",
    "\n",
    "# newDF\n",
    "better_1=hdiFile.copy()\n",
    "\n",
    "# see head\n",
    "better_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the repeated column names (HDI rank) and _NaN_. Notice also that we do not need the last three columns. Let's solve that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without the last 4 columns\n",
    "better_1.iloc[:,:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the previous result to rewrite the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then,\n",
    "better_1=better_1.iloc[:,:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have column names with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...let's get rid of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like this?\n",
    "better_1.columns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the change!\n",
    "\n",
    "BetterHeaders=better_1.columns.dropna()\n",
    "#result\n",
    "BetterHeaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting again\n",
    "\n",
    "better_1=better_1.loc[:,BetterHeaders]\n",
    "better_2=better_1.copy()\n",
    "#see\n",
    "better_2.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Using Regex for clean column names**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that the columns:\n",
    "* Have acronyms in parenthesis.\n",
    "* Have spaces between words.\n",
    "\n",
    "Let's see what can be done using _Regular Expressions_ (REGEX):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye anything between parentheses\n",
    "better_2.columns.str.replace('\\(.+\\)',\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye anything between parentheses, bye leading-trailing spaces\n",
    "better_2.columns.str.replace('\\(.+\\)',\"\", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye anything between parentheses, bye leading-trailing spaces, title case\n",
    "better_2.columns.str.replace('\\(.+\\)',\"\", regex=True).\\\n",
    "                          str.strip().\\\n",
    "                          str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep this last one for a while:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing column names\n",
    "better_2.columns=better_2.columns.str.replace('\\(.+\\)',\"\", regex=True).\\\n",
    "                          str.strip().\\\n",
    "                          str.title()\n",
    "#so\n",
    "better_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to decide how the we want as the shorter column name:\n",
    "\n",
    "a. Same title without spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_2.columns.str.replace(\" \",'',regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Some acronyms: Let's do this step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each column names splitted:\n",
    "[name.split() for name in better_2.columns[2::]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first letter of each word\n",
    "[[word[0] for word in name.split()] for name in better_2.columns[2::]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final result\n",
    "[''.join([word[0] for word in name.split()]) for name in better_2.columns[2::]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the last alternative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNames=[''.join([word[0] for word in name.split()]) for name in better_2.columns[2::]]\n",
    "better_2.columns=better_2.columns[:2].str.replace(\" \",'',regex=False).to_list()+newNames\n",
    "\n",
    "#newDF\n",
    "better_3=better_2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "better_3.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "<a id='subset'></a>\n",
    "\n",
    "### Subset data\n",
    "\n",
    "After becoming familar with the data, we know we should keep countries with ranking value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_3[~pd.isna(better_3['HdiRank'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then\n",
    "hdiSubset=better_3[~pd.isna(better_3['HdiRank'])].copy()\n",
    "\n",
    "#see\n",
    "hdiSubset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a bad row data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiSubset.drop(index=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just drop it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiSubset.drop(index=4, inplace=True)\n",
    "hdiSubset.reset_index(drop=True, inplace=True)\n",
    "#see\n",
    "hdiSubset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "<a id='missing'></a>\n",
    "\n",
    "### Missing values\n",
    "\n",
    "* **Any non standard missing values?**\n",
    "\n",
    "First check a cell that is full of non-word/non-digit characters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **try**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hdiSubset.shape[1]):\n",
    "    try:\n",
    "        print(hdiSubset.iloc[:,i][hdiSubset.iloc[:,i].str.fullmatch(\"\\W+\",na=False)])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have weird symbols, but if we had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing !\n",
    "\n",
    "badSymbols=[\"..\",'xx','tba']\n",
    "hdiSubset.replace(to_replace=badSymbols,\n",
    "               value=None,\n",
    "               inplace=True)\n",
    "\n",
    "#result\n",
    "hdiSubset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keeping complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with all missing (after the first column)\n",
    "hdiSubset[hdiSubset.iloc[:,1:].isna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with at least one missing (after the first column)\n",
    "hdiSubset[hdiSubset.iloc[:,1:].isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiClean=hdiSubset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "<a id='formatdtypes'></a>\n",
    "\n",
    "## Formatting DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore\n",
    "hdiClean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way you drop a column name (not the whole column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdiClean.columns.drop('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers have been recognised as **object** type. It might be due to having a non numeric value in one cell, or because it **had** a non-numeric value before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep all numeric columns\n",
    "\n",
    "allNumCols=hdiClean.columns.drop('Country')\n",
    "allNumCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as easy as:\n",
    "hdiClean[allNumCols]=hdiClean[allNumCols].apply(pd.to_numeric)\n",
    "hdiFormat=hdiClean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recheck\n",
    "hdiFormat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can you apply math?\n",
    "hdiFormat.drop(columns=['Country'], axis=0).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the next process, let's quickly preprocess the table we scraped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief look\n",
    "demoTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data types\n",
    "demoTable.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep some:\n",
    "someCols=demoTable.columns[~demoTable.columns.str.contains('Δ')]\n",
    "\n",
    "\n",
    "#subset\n",
    "demoTable=demoTable[someCols].copy()\n",
    "\n",
    "demoTable.columns=demoSub.columns.str.replace('\\W',\"\",regex=True)\n",
    "\n",
    "#then\n",
    "demoTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a categorical column, let's give the right data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite the levels in ascending order:\n",
    "correctLevels=['Authoritarian', 'Hybrid regime', 'Flawed democracy','Full democracy']\n",
    "#format as ordinal:\n",
    "demoTable.Regimetype=pd.Categorical(demoTable.Regimetype,categories=correctLevels,ordered=True)\n",
    "demoFormat=demoTable.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demoFormat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "\n",
    "## 3. Integrating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='merging'></a>\n",
    "\n",
    "### Basic merging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are confident we did a good cleaning and formatting, this step should be easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_on= / right_on NOT NEEDED (only when column names differ)\n",
    "HdiDemo=hdiFormat.merge(demoFormat,left_on='Country', right_on='Country')\n",
    "HdiDemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the amount of rowd **returned above**, and compare it with the amount of rows in each data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(HdiDemo),len(hdiFormat),len(demoFormat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not want to check country names, you stop here.\n",
    "\n",
    "[Home](#home)\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fuzzmerging'></a>\n",
    "\n",
    "### Fuzzy Merge\n",
    "\n",
    "\n",
    "The smallest amount of rows between two tables, is the maximum amount you expect after the merge. Let's check the key values that were not matched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyHDI=set(hdiFormat.Country)-set(demoFormat.Country)\n",
    "onlyDEMO=set(demoFormat.Country)-set(hdiFormat.Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyHDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyDEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous objects (onlyDEMO, onlyHDI) inform the values not matched in the other data frames. \n",
    "If you want to recover some of these values, you may follow these steps (you may need to install **thefuzz**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process as fz\n",
    "\n",
    "# take a country from onlyDEMO\n",
    "\n",
    "# and get the country that matches the most in OnlyHDI, show the match score!\n",
    "\n",
    "# notice I sorted onlyDEMO\n",
    "\n",
    "[(aDemoCountry,fz.extractOne(aDemoCountry, onlyHDI)) for aDemoCountry in sorted(onlyDEMO)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are countries that will not find a match, then let's subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notInHDI=['North Korea','Taiwan']\n",
    "demoFormat_sub=demoFormat[~demoFormat.Country.isin(notInHDI)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are countries that did find a match, but the process worked wrong. Let's change it by brute force:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of changes\n",
    "changesDEMO={'Czech Republic':'Czechia',\n",
    "             'Laos':\"Lao People's Democratic Republic\"}\n",
    "\n",
    "# make the replacement\n",
    "demoFormat_sub.Country.replace(to_replace=changesDEMO,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have make changes to the column values, let's redo the fuzzy-merging process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyHDI=set(hdiFormat.Country)-set(demoFormat_sub.Country)\n",
    "onlyDEMO=set(demoFormat_sub.Country)-set(hdiFormat.Country)\n",
    "\n",
    "[(aDemoCountry,fz.extractOne(aDemoCountry, onlyHDI)) for aDemoCountry in sorted(onlyDEMO)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All matches are great. Let's create a **dictionary of changes**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesDEMO={aDemoCountry:fz.extractOne(aDemoCountry, onlyHDI)[0] for aDemoCountry in sorted(onlyDEMO)}\n",
    "changesDEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace in democracy\n",
    "\n",
    "demoFormat_sub.Country.replace(to_replace=changesDEMO,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a new merge: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did you get more rows?\n",
    "HdiDemo_2=hdiFormat.merge(demoFormat_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenghts\n",
    "\n",
    "len(HdiDemo_2),len(HdiDemo), len(hdiFormat),len(demoFormat_sub),len(demoFormat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format should still be good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HdiDemo_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "\n",
    "## Prepare file for further work\n",
    "\n",
    "<a id='scaling'></a>\n",
    "\n",
    "###  Scaling\n",
    "\n",
    "It would be good to check the range of values of your numeric data. You can simply use **describe** (just requesting _min_ and _max_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HdiDemo_2.describe().loc[['min','max']].T #T for transposing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see different ranges, it would be good to request a **boxplot** (make sure to install **matplotlib** if not previously installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "HdiDemo_2.plot(kind='box', rot=90,fontsize=5)\n",
    "plt.semilogy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our concern is the numeric data. In case of categorical it is unusual to worry about it, but some cases might need some thinking.\n",
    "\n",
    "Let me get the column names of the numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "colsToScale = HdiDemo_2.select_dtypes([np.number]).columns\n",
    "\n",
    "colsToScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to produce new ranges (make sure you have previously install **scikit-learn**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_minmax = scaler.fit_transform(HdiDemo_2.loc[:,colsToScale].to_numpy())\n",
    "df_scaled = pd.DataFrame(df_minmax, columns=colsToScale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_scaled.describe().loc[['min','max']].T \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.plot(kind='box', rot=90,fontsize=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a suffix to the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.columns=df_scaled.columns+\"_mM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat to the right (instead of bottom) with axis=1\n",
    "pd.concat([HdiDemo_2,df_scaled],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is our last version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem_plus=pd.concat([HdiDemo_2,df_scaled],axis=1)\n",
    "hdidem_plus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](#home)\n",
    "______\n",
    "\n",
    "\n",
    "<a id='exporting'></a>\n",
    "\n",
    "### Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future use in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdidem_plus.to_pickle(\"hdidem_plus.pkl\")\n",
    "# you will need: DF=pd.read_pickle(\"hdidem_plus.pkl\")\n",
    "# or:\n",
    "# from urllib.request import urlopen\n",
    "# DF=pd.read_pickle(urlopen(\"https://...../hdidem_plus.pkl\"),compression=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future  use in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr('base')\n",
    "base.saveRDS(hdidem_plus,file=\"hdidem_plus.RDS\")\n",
    "\n",
    "#In R, you call it with: DF = readRDS(\"hdidem_plus.RDS\")\n",
    "#or, if read from cloud: DF = readRDS(url(\"https://...../hdidem_plus.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
